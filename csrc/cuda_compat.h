/**
 * =============================================================================
 * LightvLLM CUDA 호환성 및 메모리 최적화 매크로
 * =============================================================================
 *
 * 이 파일은 CUDA 커널에서 사용하는 메모리 접근 최적화 매크로를 정의합니다.
 *
 * 목차:
 * 1. GPU 메모리 계층 구조 이해하기
 * 2. __ldg() 함수란?
 * 3. 왜 최적화가 필요한가?
 * 4. 실제 매크로 정의
 */

#pragma once

/**
 * =============================================================================
 * 1. GPU 메모리 계층 구조 이해하기
 * =============================================================================
 *
 * GPU는 여러 단계의 메모리 계층을 가지고 있습니다:
 *
 *   [레지스터]     ← 가장 빠름 (스레드 전용, ~1 cycle)
 *        ↓
 *   [공유 메모리]   ← 매우 빠름 (블록 내 공유, ~5 cycles)
 *        ↓
 *   [L1 캐시]      ← 빠름 (SM당, ~30 cycles)
 *        ↓
 *   [L2 캐시]      ← 중간 (전체 GPU 공유, ~200 cycles)
 *        ↓
 *   [글로벌 메모리]  ← 느림 (VRAM, ~400-800 cycles)
 *
 *
 * 글로벌 메모리 접근이 가장 느린 이유:
 * - 물리적으로 GPU 칩 외부(VRAM)에 있음
 * - 대역폭은 높지만 지연(latency)이 큼
 * - 수백 클럭 사이클이 소요됨
 *
 * 따라서 CUDA 최적화의 핵심은:
 * "글로벌 메모리 접근을 최소화하고, 캐시를 최대한 활용하는 것"
 *
 *
 * =============================================================================
 * 2. __ldg() 함수란?
 * =============================================================================
 *
 * __ldg()는 "Load from Global memory through texture cache"의 약자입니다.
 *
 * 일반적인 글로벌 메모리 읽기:
 *   float value = ptr[idx];  // L1 캐시 경로 사용
 *
 * __ldg()를 사용한 읽기:
 *   float value = __ldg(&ptr[idx]);  // 텍스처 캐시 경로 사용
 *
 *
 * [텍스처 캐시란?]
 *
 * GPU는 원래 그래픽 처리를 위해 설계되었습니다.
 * 텍스처(이미지)를 빠르게 읽기 위한 전용 캐시가 있는데, 이것이 "텍스처 캐시"입니다.
 *
 * 텍스처 캐시의 특징:
 * - 읽기 전용 (Read-Only) 데이터에 최적화
 * - L1 캐시와 별개의 경로
 * - 브로드캐스트에 효율적 (여러 스레드가 같은 데이터 읽을 때)
 *
 *
 * [L1 캐시 vs 텍스처 캐시]
 *
 *                    L1 캐시              텍스처 캐시
 *   ─────────────────────────────────────────────────────
 *   읽기/쓰기        읽기+쓰기 가능            읽기 전용
 *   최적화 대상        순차 접근          랜덤 접근, 공간 지역성
 *   캐시 라인        128 바이트              32 바이트
 *   용도               범용              읽기 전용 데이터
 *
 *
 * =============================================================================
 * 3. 왜 최적화가 필요한가?
 * =============================================================================
 *
 * [문제 상황: 캐시 오염 (Cache Pollution)]
 *
 * L1 캐시는 크기가 제한되어 있습니다 (보통 SM당 128KB).
 * 읽기 전용 데이터도 L1 캐시에 들어가면, 읽기-쓰기 데이터를 위한 공간이 줄어듭니다.
 *
 * 예시 - 캐시 오염이 발생하는 경우:
 *
 *   __global__ void kernel(float* output, const float* readonly_input, ...) {
 *       // readonly_input을 읽으면 L1 캐시에 저장됨
 *       float val = readonly_input[idx];  // L1 캐시 사용
 *
 *       // output에 쓸 때도 L1 캐시가 필요한데,
 *       // readonly_input이 캐시 공간을 차지하고 있음
 *       output[idx] = val * 2;  // 캐시 미스 발생 가능
 *   }
 *
 *
 * [해결책: __ldg()로 캐시 분리]
 *
 *   __global__ void kernel(float* output, const float* readonly_input, ...) {
 *       // readonly_input을 텍스처 캐시로 읽음 → L1 캐시 오염 없음
 *       float val = __ldg(&readonly_input[idx]);  // 텍스처 캐시 사용
 *
 *       // output은 L1 캐시를 온전히 사용 가능
 *       output[idx] = val * 2;  // 캐시 히트 가능성 높음
 *   }
 *
 *
 * [실제 성능 차이]
 *
 * 읽기 전용 데이터가 많은 커널에서 __ldg() 사용 시:
 * - 5~20% 성능 향상 가능
 * - 특히 메모리 바운드(memory-bound) 커널에서 효과적
 *
 * LLM 추론에서 읽기 전용 데이터 예시:
 * - 모델 가중치 (weights)
 * - 입력 텐서 (수정하지 않는 경우)
 * - 룩업 테이블 (cos, sin 값 등)
 *
 *
 * [주의사항]
 *
 * 1. 읽기 전용 데이터에만 사용해야 함
 *    - 쓰기가 발생하는 메모리에 __ldg() 사용 시 정의되지 않은 동작
 *
 * 2. Volta 이후 GPU (SM 7.0+)에서는 효과가 줄어듦
 *    - L1과 텍스처 캐시가 통합됨
 *    - 그래도 "읽기 전용" 힌트를 주는 의미가 있음
 *
 * 3. 컴파일러 최적화와 함께 사용
 *    - const __restrict__ 포인터와 함께 사용하면 더 효과적
 *
 *
 * =============================================================================
 * 4. 실제 매크로 정의
 * =============================================================================
 */

/**
 * VLLM_LDG - 읽기 전용 글로벌 메모리 로드 매크로
 *
 * 사용법:
 *   const float* input = ...;
 *   float value = VLLM_LDG(&input[idx]);
 *
 * 동작:
 *   __ldg(arg)를 호출하여 텍스처 캐시 경로로 메모리를 읽습니다.
 *
 * 언제 사용하는가:
 *   - 커널 내에서 절대 수정하지 않는 데이터를 읽을 때
 *   - 모델 가중치, 입력 데이터, 상수 테이블 등
 *
 * 예시 (RoPE 커널에서):
 *   // cos, sin 값은 미리 계산된 읽기 전용 테이블
 *   float cos_val = VLLM_LDG(&cos_table[pos * head_dim + i]);
 *   float sin_val = VLLM_LDG(&sin_table[pos * head_dim + i]);
 *
 *   // query, key도 이 커널에서는 읽기만 함 (출력은 별도 버퍼)
 *   float q = VLLM_LDG(&query[idx]);
 */
#define VLLM_LDG(arg) __ldg(arg)


/**
 * WARP_SIZE - 워프 크기 상수
 *
 * 워프(Warp)란?
 *   NVIDIA GPU에서 동시에 같은 명령어를 실행하는 스레드 그룹입니다.
 *   NVIDIA GPU에서는 항상 32개의 스레드가 하나의 워프를 구성합니다.
 *
 * 왜 중요한가?
 *   - 워프 내 스레드들은 SIMT(Single Instruction, Multiple Threads) 방식으로 실행
 *   - 워프 단위로 스케줄링되므로, 32의 배수로 스레드를 구성하면 효율적
 *   - 워프 내 분기(if-else)가 발생하면 "워프 다이버전스"로 성능 저하
 *
 * 사용 예시:
 *   - 리덕션(reduction) 연산에서 워프 단위 최적화
 *   - 블록 크기를 WARP_SIZE의 배수로 설정
 */
#define WARP_SIZE 32
